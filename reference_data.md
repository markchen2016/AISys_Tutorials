###### 系列文章
1. 《Transformers快速入门》 https://transformers.run/  
**Abstract** 待续  
**阅读状态** doing

###### 预训练技术  
1. 《从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史》 https://zhuanlan.zhihu.com/p/49271699  
**Abstract** 介绍了自然语言处理中的预训练技术的发展，其中主要介绍了 Word2Vec（获取词向量）、ELMO（新增双向LSTM，给词向量新增上下文语义特征、句法特征，解决多义词相同embedding问题，双向语言模型）、GPT-1（预训练+下游任务Fine-tuning两阶段，使用Transformer特征抽取器，单向语言模型）、Bert（使用Transformer特征抽取、通过mask根据上下文猜词实现双向语义特征提取，双向语言模型）  
**阅读状态** done
2. 《》